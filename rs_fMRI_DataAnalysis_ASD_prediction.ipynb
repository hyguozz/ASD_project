{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MoAlRJovX0YH"
   },
   "source": [
    "## Summarized Report\n",
    "## Hongyu Guo\n",
    "## May, 2024\n",
    "\n",
    "### Dataset\n",
    "\n",
    "The dataset used in this project is sourced from the Autism Brain Imaging Data Exchange (ABIDE). The data has been preprocessed using Cameron Craddock's 200 ROI parcellation atlas, which includes the following key steps:\n",
    "\n",
    "1. **Atlas and ROIs**:\n",
    "   - Utilized Cameron Craddock's 200 ROI parcellation atlas.\n",
    "   - Included 200 Regions of Interest (ROIs).\n",
    "\n",
    "2. **Preprocessing Pipeline**:\n",
    "   - Applied the CPAC preprocessing pipeline.\n",
    "   - Implemented band-pass filtering (0.01 - 0.1 Hz) after nuisance variable regression.\n",
    "   - Incorporated global mean signal correction during nuisance variable regression for strategies that included global signal correction.\n",
    "\n",
    "### Data Overview\n",
    "\n",
    "- **Sample Distribution**:\n",
    "  - ASD (Autism Spectrum Disorder): 408 samples\n",
    "  - TD (Typically Developing): 486 samples\n",
    "- **Time Steps**: Ranged from 78 to 316\n",
    "- **ROIs**: 200\n",
    "\n",
    "### Data Cleaning\n",
    "\n",
    "To ensure data quality, the following cleaning steps were applied:\n",
    "\n",
    "- Samples with any Pearson Correlation Coefficient (PCC) value as NaN were removed.\n",
    "- Post-cleaning Sample Counts:\n",
    "  - ASD: 391\n",
    "  - TD: 468\n",
    "\n",
    "### Network Generation\n",
    "\n",
    "The network features were generated as follows:\n",
    "\n",
    "- Calculated the PCC between pairs of ROIs.\n",
    "- Saved the upper diagonal of the PCC matrix (excluding the diagonal values) as the features for each subject.\n",
    "\n",
    "# Model Development\n",
    "### Model 1. Semi-supervised Autocoder classification model\n",
    "\n",
    "### Model 2. Pre-train a VAE model followed by adding the MLP for ASD classification.\n",
    "\n",
    "1. Train the VAE to reconstruct the input data.\n",
    "2. Integrate the MLP into the Pre-trained VAE for ASD Classification.\n",
    "\n",
    "\n",
    "### Results\n",
    "\n",
    "The classification accuracy was around 66%. This suggests that further data cleaning, preprocessing, and model optimization are needed, potentially indicating some important steps or techniques were missed from the literature.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LjhhxiPzq_hQ",
    "outputId": "231b0b1e-047f-459e-bbcf-033da2c58db2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount(\"/content/drive/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5ARlkWSH2RF0",
    "outputId": "14b5a6b7-d12a-46a4-b90c-b01e0a9959d4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found GPU at: /device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "device_name = tf.test.gpu_device_name()\n",
    "if device_name != '/device:GPU:0':\n",
    "  raise SystemError('GPU device not found')\n",
    "print('Found GPU at: {}'.format(device_name))\n",
    "import time\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YXNRCzrNx_23",
    "outputId": "35685d11-6957-48ab-e4e1-bc205f759b7c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset size: 644\n",
      "Validation dataset size: 33\n",
      "Testing dataset size: 182\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "# Load the data\n",
    "td_path = '/content/drive/My Drive/ASD_project_2024/pcc_TD_cleaned.pkl'\n",
    "asd_path = '/content/drive/My Drive/ASD_project_2024/pcc_ASD_cleaned.pkl'\n",
    "\n",
    "with open(td_path, 'rb') as file:\n",
    "    td_data = pickle.load(file)\n",
    "\n",
    "with open(asd_path, 'rb') as file:\n",
    "    asd_data = pickle.load(file)\n",
    "\n",
    "# Transform the data to [0, 1] range\n",
    "td_data = (td_data + 1) / 2\n",
    "asd_data = (asd_data + 1) / 2\n",
    "\n",
    "# Create labels\n",
    "td_labels = np.zeros(td_data.shape[0])\n",
    "asd_labels = np.ones(asd_data.shape[0])\n",
    "\n",
    "# Combine the data\n",
    "X = np.vstack((td_data, asd_data))\n",
    "y = np.concatenate((td_labels, asd_labels))\n",
    "\n",
    "# Split the data into training, testing, and validation sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "X_test, X_val, y_test, y_val = train_test_split(X_test, y_test, test_size=0.15, random_state=42)\n",
    "\n",
    "# Print dataset sizes for debugging\n",
    "print(f\"Training dataset size: {X_train.shape[0]}\")\n",
    "print(f\"Validation dataset size: {X_val.shape[0]}\")\n",
    "print(f\"Testing dataset size: {X_test.shape[0]}\")\n",
    "\n",
    "# Convert data to PyTorch tensors\n",
    "train_x = torch.from_numpy(X_train).float()\n",
    "train_y = torch.from_numpy(y_train).float().view(-1, 1)\n",
    "train_dataset = TensorDataset(train_x, train_y)\n",
    "\n",
    "test_x = torch.from_numpy(X_test).float()\n",
    "test_y = torch.from_numpy(y_test).float().view(-1, 1)\n",
    "test_dataset = TensorDataset(test_x, test_y)\n",
    "\n",
    "val_x = torch.from_numpy(X_val).float()\n",
    "val_y = torch.from_numpy(y_val).float().view(-1, 1)\n",
    "val_dataset = TensorDataset(val_x, val_y)\n",
    "\n",
    "# Create data loaders\n",
    "bs = 32  # Example batch size\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=bs, shuffle=True, drop_last=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=bs, shuffle=True, drop_last=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=bs, shuffle=True, drop_last=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "Gl6VhbIHqprs"
   },
   "outputs": [],
   "source": [
    "def to_var(x):\n",
    "    if torch.cuda.is_available():\n",
    "        x = x.cuda()\n",
    "    return Variable(x)\n",
    "\n",
    "def flatten(x):\n",
    "    return to_var(x.view(x.size(0), -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "smaNWSaYqvAt",
    "outputId": "e007273d-84a3-4a7b-868a-5b50f41c48fb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19900"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_size = X_train.shape[1]\n",
    "feature_size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yzvmg1xOkKEp",
    "outputId": "be7ff9c4-44a1-4563-bad1-387ed77d2cb6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((468, 19900), (391, 19900))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "td_data.shape, asd_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "STJ115G4RFtk"
   },
   "source": [
    "# Method 1\n",
    "# Semi-supervised Autocoder classification model\n",
    "## Different from the paper, VAE is used in this code.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DhxPN07j7dK5",
    "outputId": "311bf89c-0552-494c-cf3b-71ccc095a83b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing weight: 0.60\n",
      "Training --- Epoch 1/10, VAE Loss: 0.9095546483993531, ASD Loss: 0.660964635014534, Accuracy: 61.41%\n",
      "Validation - Epoch 1/10, VAE Loss: 0.7109365463256836, ASD Loss: 0.6686631441116333, Accuracy: 56.25%\n",
      "Training --- Epoch 2/10, VAE Loss: 0.9122982919216156, ASD Loss: 0.4238467141985893, Accuracy: 86.25%\n",
      "Validation - Epoch 2/10, VAE Loss: 0.7453729510307312, ASD Loss: 0.574348509311676, Accuracy: 78.12%\n",
      "Training --- Epoch 3/10, VAE Loss: 0.9073170572519302, ASD Loss: 0.31150773391127584, Accuracy: 94.38%\n",
      "Validation - Epoch 3/10, VAE Loss: 0.7780651450157166, ASD Loss: 0.625944197177887, Accuracy: 59.38%\n",
      "Training --- Epoch 4/10, VAE Loss: 0.9023516118526459, ASD Loss: 0.21313233226537703, Accuracy: 99.06%\n",
      "Validation - Epoch 4/10, VAE Loss: 0.7989895939826965, ASD Loss: 0.8695805668830872, Accuracy: 46.88%\n",
      "Training --- Epoch 5/10, VAE Loss: 0.8951648026704788, ASD Loss: 0.15752620473504067, Accuracy: 100.00%\n",
      "Validation - Epoch 5/10, VAE Loss: 0.77845299243927, ASD Loss: 0.6705989837646484, Accuracy: 65.62%\n",
      "Training --- Epoch 6/10, VAE Loss: 0.8843518227338791, ASD Loss: 0.14009136520326138, Accuracy: 100.00%\n",
      "Validation - Epoch 6/10, VAE Loss: 0.7689110636711121, ASD Loss: 0.5756357908248901, Accuracy: 65.62%\n",
      "Training --- Epoch 7/10, VAE Loss: 0.8729982644319534, ASD Loss: 0.12262688092887401, Accuracy: 100.00%\n",
      "Validation - Epoch 7/10, VAE Loss: 0.7650782465934753, ASD Loss: 0.6950153112411499, Accuracy: 53.12%\n",
      "Training --- Epoch 8/10, VAE Loss: 0.8590137869119644, ASD Loss: 0.127538226172328, Accuracy: 100.00%\n",
      "Validation - Epoch 8/10, VAE Loss: 0.7585219144821167, ASD Loss: 0.6529982089996338, Accuracy: 62.50%\n",
      "Training --- Epoch 9/10, VAE Loss: 0.8516484886407852, ASD Loss: 0.11523499861359596, Accuracy: 99.84%\n",
      "Validation - Epoch 9/10, VAE Loss: 0.7518417835235596, ASD Loss: 0.6154075264930725, Accuracy: 65.62%\n",
      "Training --- Epoch 10/10, VAE Loss: 0.8428731441497803, ASD Loss: 0.10885288901627063, Accuracy: 100.00%\n",
      "Validation - Epoch 10/10, VAE Loss: 0.7490366101264954, ASD Loss: 0.545376181602478, Accuracy: 71.88%\n",
      "----------------\n",
      "Test Results - ASD Loss: 0.6477870225906373, Accuracy: 68.75%\n"
     ]
    }
   ],
   "source": [
    "### May, 2024\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "\n",
    "# Define the VAE model\n",
    "class VAE(nn.Module):\n",
    "    def __init__(self, input_dim, h_dim, z_dim, mlp_dim):\n",
    "        super(VAE, self).__init__()\n",
    "        # Encoder\n",
    "        self.encoder1 = nn.Sequential(\n",
    "            nn.Linear(input_dim, h_dim),\n",
    "            nn.BatchNorm1d(h_dim),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(0.3))\n",
    "\n",
    "        self.encoder2 = nn.Sequential(\n",
    "            nn.Linear(h_dim, z_dim * 2))\n",
    "\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(z_dim, h_dim),\n",
    "            nn.BatchNorm1d(h_dim),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(h_dim, input_dim),\n",
    "            nn.Sigmoid())\n",
    "\n",
    "        self.task2 = nn.Sequential(\n",
    "            nn.Linear(z_dim, mlp_dim),\n",
    "            nn.BatchNorm1d(mlp_dim),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(mlp_dim, 1),\n",
    "            nn.Sigmoid())\n",
    "\n",
    "    def reparameterize(self, mu, logvar):\n",
    "        std = logvar.mul(0.5).exp_()\n",
    "        esp = Variable(torch.randn(*mu.size())).to(mu.device)\n",
    "        z = mu + std * esp\n",
    "        return z\n",
    "\n",
    "    def forward(self, x):\n",
    "        h = self.encoder1(x)\n",
    "        h = self.encoder2(h)\n",
    "        mu, logvar = torch.chunk(h, 2, dim=1)\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        pre_ASD = self.task2(z)\n",
    "        return self.decoder(z), mu, logvar, pre_ASD\n",
    "\n",
    "\n",
    "\n",
    "# Set the hyperparameters\n",
    "input_dim = X_train.shape[1]\n",
    "h_dim = 1000\n",
    "z_dim = 600\n",
    "mlp_dim = 60\n",
    "\n",
    "num_epochs = 10\n",
    "learning_rate = 0.0001\n",
    "weights = [0.6]\n",
    "\n",
    "model = VAE(input_dim, h_dim, z_dim, mlp_dim)\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "\n",
    "# Function to calculate accuracy\n",
    "def calculate_accuracy(predicted, target):\n",
    "    predicted = (predicted > 0.5).float()\n",
    "    correct = (predicted == target).sum().item()\n",
    "    return correct / target.size(0)\n",
    "\n",
    "# Grid search for the best weight\n",
    "for weight in weights:\n",
    "    print(f\"Testing weight: {weight:.2f}\")\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        train_loss_VAE = 0.0\n",
    "        train_loss_ASD = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        for batch_idx, (data, target) in enumerate(train_loader):\n",
    "            data = data.to(device)\n",
    "            target = target.to(device).float().view(-1, 1)\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            recon_x, mu, logvar, pre_ASD = model(data)\n",
    "\n",
    "            # Reconstruction loss\n",
    "            recon_loss = F.binary_cross_entropy(recon_x, data, reduction='mean')\n",
    "\n",
    "            # KL divergence\n",
    "            kld = -0.5 * torch.mean(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "            loss_task1 = recon_loss + kld\n",
    "\n",
    "            # Classification loss\n",
    "            loss_task2 = F.binary_cross_entropy(pre_ASD, target, reduction='mean')\n",
    "\n",
    "            # Total loss with weight\n",
    "            loss = (1 - weight) * loss_task1 + weight * loss_task2\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss_VAE += loss_task1.item()\n",
    "            train_loss_ASD += loss_task2.item()\n",
    "\n",
    "            # Calculate accuracy\n",
    "            correct += calculate_accuracy(pre_ASD.detach(), target) * target.size(0)\n",
    "            total += target.size(0)\n",
    "\n",
    "        train_accuracy = 100 * correct / total\n",
    "        print(f\"Training --- Epoch {epoch + 1}/{num_epochs}, VAE Loss: {train_loss_VAE / len(train_loader)}, ASD Loss: {train_loss_ASD / len(train_loader)}, Accuracy: {train_accuracy:.2f}%\")\n",
    "\n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_loss_VAE = 0.0\n",
    "        val_loss_ASD = 0.0\n",
    "        val_correct = 0\n",
    "        val_total = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for batch_idx, (data, target) in enumerate(val_loader):\n",
    "                data = data.to(device)\n",
    "                target = target.to(device).float().view(-1, 1)\n",
    "\n",
    "                recon_x, mu, logvar, pre_ASD = model(data)\n",
    "\n",
    "                # Reconstruction loss\n",
    "                recon_loss = F.binary_cross_entropy(recon_x, data, reduction='mean')\n",
    "\n",
    "                # KL divergence\n",
    "                kld = -0.5 * torch.mean(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "                loss_task1 = recon_loss + kld\n",
    "\n",
    "                # Classification loss\n",
    "                loss_task2 = F.binary_cross_entropy(pre_ASD, target, reduction='mean')\n",
    "\n",
    "                val_loss_VAE += loss_task1.item()\n",
    "                val_loss_ASD += loss_task2.item()\n",
    "\n",
    "                # Calculate accuracy\n",
    "                val_correct += calculate_accuracy(pre_ASD, target) * target.size(0)\n",
    "                val_total += target.size(0)\n",
    "\n",
    "        if val_total > 0:\n",
    "            val_accuracy = 100 * val_correct / val_total\n",
    "            print(f\"Validation - Epoch {epoch + 1}/{num_epochs}, VAE Loss: {val_loss_VAE / len(val_loader)}, ASD Loss: {val_loss_ASD / len(val_loader)}, Accuracy: {val_accuracy:.2f}%\")\n",
    "        else:\n",
    "            print(f\"Validation - Epoch {epoch + 1}/{num_epochs}, No validation samples processed.\")\n",
    "\n",
    "# Testing after training\n",
    "model.eval()\n",
    "test_loss_ASD = 0.0\n",
    "test_correct = 0\n",
    "test_total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_idx, (data, target) in enumerate(test_loader):\n",
    "        data = data.to(device)\n",
    "        target = target.to(device).float().view(-1, 1)\n",
    "\n",
    "        _, _, _, pre_ASD = model(data)\n",
    "\n",
    "        # Classification loss\n",
    "        loss_task2 = F.binary_cross_entropy(pre_ASD, target, reduction='mean')\n",
    "        test_loss_ASD += loss_task2.item()\n",
    "\n",
    "        # Calculate accuracy\n",
    "        test_correct += calculate_accuracy(pre_ASD, target) * target.size(0)\n",
    "        test_total += target.size(0)\n",
    "\n",
    "if test_total > 0:\n",
    "    test_accuracy = 100 * test_correct / test_total\n",
    "    print(\"----------------\")\n",
    "    print(f\"Test Results - ASD Loss: {test_loss_ASD / len(test_loader)}, Accuracy: {test_accuracy:.2f}%\")\n",
    "else:\n",
    "    print(\"No test samples processed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mSMLqnpmFPUw"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pJoHayoqHROx"
   },
   "source": [
    "# Method 2:\n",
    "# The semi-supervised learning by adding the MLP for ASD classification into the pre-trained VAE model.\n",
    "\n",
    "1. Train the VAE to reconstruct the input data.\n",
    "2. Integrate the MLP into the Pre-trained VAE for ASD Classification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AzooVjI3HLB8"
   },
   "source": [
    "# Step 1: Train the VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zIB4C8mwFPjw",
    "outputId": "6b9d4e6d-871b-45cb-e8a8-ef12a1d7bf9f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20, Loss: 0.8618254005908966\n",
      "Epoch 2/20, Loss: 0.8046551197767258\n",
      "Epoch 3/20, Loss: 0.778367668390274\n",
      "Epoch 4/20, Loss: 0.7667982012033463\n",
      "Epoch 5/20, Loss: 0.7586871802806854\n",
      "Epoch 6/20, Loss: 0.7530590772628785\n",
      "Epoch 7/20, Loss: 0.748719933629036\n",
      "Epoch 8/20, Loss: 0.7450314700603485\n",
      "Epoch 9/20, Loss: 0.7412677139043808\n",
      "Epoch 10/20, Loss: 0.7382235944271087\n",
      "Epoch 11/20, Loss: 0.735998558998108\n",
      "Epoch 12/20, Loss: 0.7336918354034424\n",
      "Epoch 13/20, Loss: 0.7315237104892731\n",
      "Epoch 14/20, Loss: 0.7292782127857208\n",
      "Epoch 15/20, Loss: 0.7274185061454773\n",
      "Epoch 16/20, Loss: 0.725600180029869\n",
      "Epoch 17/20, Loss: 0.7239365667104721\n",
      "Epoch 18/20, Loss: 0.7222286820411682\n",
      "Epoch 19/20, Loss: 0.7205595374107361\n",
      "Epoch 20/20, Loss: 0.7196021974086761\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "\n",
    "# Define the VAE model\n",
    "class VAE(nn.Module):\n",
    "    def __init__(self, input_dim, h_dim, z_dim):\n",
    "        super(VAE, self).__init__()\n",
    "        # Encoder\n",
    "        self.encoder1 = nn.Sequential(\n",
    "            nn.Linear(input_dim, h_dim),\n",
    "            nn.BatchNorm1d(h_dim),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(0.3))\n",
    "\n",
    "        self.encoder2 = nn.Sequential(\n",
    "            nn.Linear(h_dim, z_dim * 2))\n",
    "\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(z_dim, h_dim),\n",
    "            nn.BatchNorm1d(h_dim),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(h_dim, input_dim),\n",
    "            nn.Sigmoid())\n",
    "\n",
    "    def reparameterize(self, mu, logvar):\n",
    "        std = logvar.mul(0.5).exp_()\n",
    "        esp = Variable(torch.randn(*mu.size())).to(mu.device)\n",
    "        z = mu + std * esp\n",
    "        return z\n",
    "\n",
    "    def forward(self, x):\n",
    "        h = self.encoder1(x)\n",
    "        h = self.encoder2(h)\n",
    "        mu, logvar = torch.chunk(h, 2, dim=1)\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        return self.decoder(z), mu, logvar\n",
    "\n",
    "# Set the hyperparameters\n",
    "input_dim = X_train.shape[1]\n",
    "h_dim = 1000\n",
    "z_dim = 600\n",
    "\n",
    "num_epochs = 20\n",
    "learning_rate = 0.0001\n",
    "\n",
    "vae = VAE(input_dim, h_dim, z_dim)\n",
    "optimizer = optim.Adam(vae.parameters(), lr=learning_rate)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "vae.to(device)\n",
    "\n",
    "# Train the VAE\n",
    "for epoch in range(num_epochs):\n",
    "    vae.train()\n",
    "    train_loss = 0.0\n",
    "\n",
    "    for batch_idx, (data, _) in enumerate(train_loader):\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        recon_x, mu, logvar = vae(data)\n",
    "\n",
    "        # Reconstruction loss\n",
    "        recon_loss = F.binary_cross_entropy(recon_x, data, reduction='mean')\n",
    "\n",
    "        # KL divergence\n",
    "        kld = -0.5 * torch.mean(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "        loss = recon_loss + kld\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs}, Loss: {train_loss / len(train_loader)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VaI6nNfEHDNW"
   },
   "source": [
    "# Step 2: Integrate the MLP into the Pre-trained VAE for ASD Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xDkTy44-UNxv",
    "outputId": "a69b5fc2-8c9f-4444-fd0b-84dcd27d4b3d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training --- Epoch 1/20, VAE Loss: 0.8798136830329895, ASD Loss: 0.3315301775932312, Accuracy: 94.06%\n",
      "Validation - Epoch 1/20, VAE Loss: 0.07620536535978317, ASD Loss: 0.5184755921363831, Accuracy: 78.12%\n",
      "Training --- Epoch 2/20, VAE Loss: 0.8538363665342331, ASD Loss: 0.17242252826690674, Accuracy: 100.00%\n",
      "Validation - Epoch 2/20, VAE Loss: 0.07477930188179016, ASD Loss: 0.5550687909126282, Accuracy: 68.75%\n",
      "Training --- Epoch 3/20, VAE Loss: 0.8199673473834992, ASD Loss: 0.16685220524668692, Accuracy: 99.84%\n",
      "Validation - Epoch 3/20, VAE Loss: 0.07494974136352539, ASD Loss: 0.4892743229866028, Accuracy: 81.25%\n",
      "Training --- Epoch 4/20, VAE Loss: 0.8069587856531143, ASD Loss: 0.15332339107990264, Accuracy: 99.84%\n",
      "Validation - Epoch 4/20, VAE Loss: 0.07308287173509598, ASD Loss: 0.5494983196258545, Accuracy: 71.88%\n",
      "Training --- Epoch 5/20, VAE Loss: 0.7977668821811676, ASD Loss: 0.1439684960991144, Accuracy: 100.00%\n",
      "Validation - Epoch 5/20, VAE Loss: 0.07251542806625366, ASD Loss: 0.5277096033096313, Accuracy: 75.00%\n",
      "Training --- Epoch 6/20, VAE Loss: 0.7921698093414307, ASD Loss: 0.14355068393051623, Accuracy: 100.00%\n",
      "Validation - Epoch 6/20, VAE Loss: 0.07228928059339523, ASD Loss: 0.5375629663467407, Accuracy: 75.00%\n",
      "Training --- Epoch 7/20, VAE Loss: 0.7869095832109452, ASD Loss: 0.1371877495199442, Accuracy: 99.69%\n",
      "Validation - Epoch 7/20, VAE Loss: 0.07184150815010071, ASD Loss: 0.5522634387016296, Accuracy: 71.88%\n",
      "Training --- Epoch 8/20, VAE Loss: 0.7836404263973236, ASD Loss: 0.13508035242557526, Accuracy: 99.84%\n",
      "Validation - Epoch 8/20, VAE Loss: 0.07177824527025223, ASD Loss: 0.5629147291183472, Accuracy: 75.00%\n",
      "Training --- Epoch 9/20, VAE Loss: 0.7823199063539505, ASD Loss: 0.12390688844025136, Accuracy: 100.00%\n",
      "Validation - Epoch 9/20, VAE Loss: 0.07148313522338867, ASD Loss: 0.5825150012969971, Accuracy: 71.88%\n",
      "Training --- Epoch 10/20, VAE Loss: 0.7764700651168823, ASD Loss: 0.11943800784647465, Accuracy: 100.00%\n",
      "Validation - Epoch 10/20, VAE Loss: 0.07171481102705002, ASD Loss: 0.5655099153518677, Accuracy: 75.00%\n",
      "Training --- Epoch 11/20, VAE Loss: 0.774504891037941, ASD Loss: 0.10223027095198631, Accuracy: 100.00%\n",
      "Validation - Epoch 11/20, VAE Loss: 0.07158330082893372, ASD Loss: 0.5431160926818848, Accuracy: 65.62%\n",
      "Training --- Epoch 12/20, VAE Loss: 0.770816034078598, ASD Loss: 0.1029820792376995, Accuracy: 100.00%\n",
      "Validation - Epoch 12/20, VAE Loss: 0.07193003594875336, ASD Loss: 0.5037389993667603, Accuracy: 78.12%\n",
      "Training --- Epoch 13/20, VAE Loss: 0.7681652694940567, ASD Loss: 0.10106390528380871, Accuracy: 99.84%\n",
      "Validation - Epoch 13/20, VAE Loss: 0.07273387163877487, ASD Loss: 0.6076734066009521, Accuracy: 71.88%\n",
      "Training --- Epoch 14/20, VAE Loss: 0.7650379359722137, ASD Loss: 0.10353069752454758, Accuracy: 99.38%\n",
      "Validation - Epoch 14/20, VAE Loss: 0.07254576683044434, ASD Loss: 0.6744362115859985, Accuracy: 59.38%\n",
      "Training --- Epoch 15/20, VAE Loss: 0.7666428118944169, ASD Loss: 0.0945086743682623, Accuracy: 99.69%\n",
      "Validation - Epoch 15/20, VAE Loss: 0.07149071246385574, ASD Loss: 0.5683993697166443, Accuracy: 62.50%\n",
      "Training --- Epoch 16/20, VAE Loss: 0.7652081072330474, ASD Loss: 0.08891142010688782, Accuracy: 100.00%\n",
      "Validation - Epoch 16/20, VAE Loss: 0.07135464251041412, ASD Loss: 0.6009984016418457, Accuracy: 75.00%\n",
      "Training --- Epoch 17/20, VAE Loss: 0.763625156879425, ASD Loss: 0.08844881877303123, Accuracy: 100.00%\n",
      "Validation - Epoch 17/20, VAE Loss: 0.07083868235349655, ASD Loss: 0.44758522510528564, Accuracy: 75.00%\n",
      "Training --- Epoch 18/20, VAE Loss: 0.761648741364479, ASD Loss: 0.08495600242167711, Accuracy: 100.00%\n",
      "Validation - Epoch 18/20, VAE Loss: 0.07126768678426743, ASD Loss: 0.6114145517349243, Accuracy: 75.00%\n",
      "Training --- Epoch 19/20, VAE Loss: 0.7612773180007935, ASD Loss: 0.07732015773653984, Accuracy: 100.00%\n",
      "Validation - Epoch 19/20, VAE Loss: 0.07181456685066223, ASD Loss: 0.8417941927909851, Accuracy: 53.12%\n",
      "Training --- Epoch 20/20, VAE Loss: 0.7562717378139496, ASD Loss: 0.07291074190288782, Accuracy: 100.00%\n",
      "Validation - Epoch 20/20, VAE Loss: 0.07099667191505432, ASD Loss: 0.5717859268188477, Accuracy: 71.88%\n",
      "Test Results - ASD Loss: 0.727783453464508, Accuracy: 66.88%\n"
     ]
    }
   ],
   "source": [
    "# Add MLP for ASD classification into the pre-trained VAE\n",
    "class VAEWithMLP(nn.Module):\n",
    "    def __init__(self, vae, z_dim, mlp_dim):\n",
    "        super(VAEWithMLP, self).__init__()\n",
    "        self.vae = vae\n",
    "        self.task2 = nn.Sequential(\n",
    "            nn.Linear(z_dim, mlp_dim),\n",
    "            nn.BatchNorm1d(mlp_dim),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(mlp_dim, 1),\n",
    "            nn.Sigmoid())\n",
    "\n",
    "    def forward(self, x):\n",
    "        recon_x, mu, logvar = self.vae(x)\n",
    "        z = self.vae.reparameterize(mu, logvar)\n",
    "        pre_ASD = self.task2(z)\n",
    "        return recon_x, mu, logvar, pre_ASD\n",
    "\n",
    "mlp_dim = 60\n",
    "vae_with_mlp = VAEWithMLP(vae, z_dim, mlp_dim)\n",
    "optimizer = optim.Adam(vae_with_mlp.parameters(), lr=learning_rate)\n",
    "vae_with_mlp.to(device)\n",
    "\n",
    "# Function to calculate accuracy\n",
    "def calculate_accuracy(predicted, target):\n",
    "    predicted = (predicted > 0.5).float()\n",
    "    correct = (predicted == target).sum().item()\n",
    "    return correct / target.size(0)\n",
    "\n",
    "# Training the VAE with auxiliary learning for ASD classification\n",
    "for epoch in range(num_epochs):\n",
    "    vae_with_mlp.train()\n",
    "    train_loss_VAE = 0.0\n",
    "    train_loss_ASD = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data = data.to(device)\n",
    "        target = target.to(device).float().view(-1, 1)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        recon_x, mu, logvar, pre_ASD = vae_with_mlp(data)\n",
    "\n",
    "        # Reconstruction loss\n",
    "        recon_loss = F.binary_cross_entropy(recon_x, data, reduction='mean')\n",
    "\n",
    "        # KL divergence\n",
    "        kld = -0.5 * torch.mean(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "        loss_task1 = recon_loss + kld\n",
    "\n",
    "        # Classification loss\n",
    "        loss_task2 = F.binary_cross_entropy(pre_ASD, target, reduction='mean')\n",
    "\n",
    "\n",
    "        # Total loss with weight\n",
    "        loss = (1 - weight) * loss_task1 + weight * loss_task2\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss_VAE += loss_task1.item()\n",
    "        train_loss_ASD += loss_task2.item()\n",
    "\n",
    "        # Calculate accuracy\n",
    "        correct += calculate_accuracy(pre_ASD.detach(), target) * target.size(0)\n",
    "        total += target.size(0)\n",
    "\n",
    "    train_accuracy = 100 * correct / total\n",
    "    print(f\"Training --- Epoch {epoch + 1}/{num_epochs}, VAE Loss: {train_loss_VAE / len(train_loader)}, ASD Loss: {train_loss_ASD / len(train_loader)}, Accuracy: {train_accuracy:.2f}%\")\n",
    "\n",
    "    # Validation\n",
    "    vae_with_mlp.eval()\n",
    "    val_loss_VAE = 0.0\n",
    "    val_loss_ASD = 0.0\n",
    "    val_correct = 0\n",
    "    val_total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (data, target) in enumerate(val_loader):\n",
    "            data = data.to(device)\n",
    "            target = target.to(device).float().view(-1, 1)\n",
    "\n",
    "            recon_x, mu, logvar, pre_ASD = vae_with_mlp(data)\n",
    "\n",
    "            # Reconstruction loss\n",
    "            recon_loss = F.binary_cross_entropy(recon_x, data, reduction='mean')\n",
    "\n",
    "            # KL divergence\n",
    "            kld = -0.5 * torch.mean(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "            loss_task1 = recon_loss + kld\n",
    "\n",
    "            # Classification loss\n",
    "            loss_task2 = F.binary_cross_entropy(pre_ASD, target, reduction='mean')\n",
    "\n",
    "            # Apply scaling factor to VAE loss\n",
    "            loss_task1 *= vae_weight\n",
    "\n",
    "            val_loss_VAE += loss_task1.item()\n",
    "            val_loss_ASD += loss_task2.item()\n",
    "\n",
    "            # Calculate accuracy\n",
    "            val_correct += calculate_accuracy(pre_ASD, target) * target.size(0)\n",
    "            val_total += target.size(0)\n",
    "\n",
    "    if val_total > 0:\n",
    "        val_accuracy = 100 * val_correct / val_total\n",
    "        print(f\"Validation - Epoch {epoch + 1}/{num_epochs}, VAE Loss: {val_loss_VAE / len(val_loader)}, ASD Loss: {val_loss_ASD / len(val_loader)}, Accuracy: {val_accuracy:.2f}%\")\n",
    "    else:\n",
    "        print(f\"Validation - Epoch {epoch + 1}/{num_epochs}, No validation samples processed.\")\n",
    "\n",
    "# Testing after training\n",
    "vae_with_mlp.eval()\n",
    "test_loss_ASD = 0.0\n",
    "test_correct = 0\n",
    "test_total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_idx, (data, target) in enumerate(test_loader):\n",
    "        data = data.to(device)\n",
    "        target = target.to(device).float().view(-1, 1)\n",
    "\n",
    "        _, _, _, pre_ASD = vae_with_mlp(data)\n",
    "\n",
    "        # Classification loss\n",
    "        loss_task2 = F.binary_cross_entropy(pre_ASD, target, reduction='mean')\n",
    "        test_loss_ASD += loss_task2.item()\n",
    "\n",
    "        # Calculate accuracy\n",
    "        test_correct += calculate_accuracy(pre_ASD, target) * target.size(0)\n",
    "        test_total += target.size(0)\n",
    "\n",
    "if test_total > 0:\n",
    "    test_accuracy = 100 * test_correct / test_total\n",
    "    print(f\"Test Results - ASD Loss: {test_loss_ASD / len(test_loader)}, Accuracy: {test_accuracy:.2f}%\")\n",
    "else:\n",
    "    print(\"No test samples processed.\")\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
